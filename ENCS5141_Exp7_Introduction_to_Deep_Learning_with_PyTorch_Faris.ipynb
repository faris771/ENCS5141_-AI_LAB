{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Faris Abufarha\n",
        "# 1200546"
      ],
      "metadata": {
        "id": "xWA9DwFLpZpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z7yMMoZRJRht"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Initialization"
      ],
      "metadata": {
        "id": "F3BV5h17Jlas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "-Jel89BkJmPt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "Xps3L_QbJqiM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCydjmpAJteF",
        "outputId": "c95a168d-bda1-4c01-ec08-d6ba062abb57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5958, 0.7047],\n",
            "        [0.7476, 0.4285]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHNKP6FRJ3nk",
        "outputId": "e0f6f35f-2323-46fa-c95f-f288f5f7c878"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.1174, 0.0084, 0.5136],\n",
            "        [0.4914, 0.2966, 0.7254]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Attributes"
      ],
      "metadata": {
        "id": "t3X8epsyJ9rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgHYuyToJ-V1",
        "outputId": "9e6cde03-0135-4972-ecc0-7bfe71e97a89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operations"
      ],
      "metadata": {
        "id": "CW-yEjGCKJJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "PVkhf4VFKJhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8142d26-1b9b-4be1-fb67-144a254d49d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR3VCZdJKPGE",
        "outputId": "f51700a0-1e63-40c6-ba25-96583d1aff2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oE7Tl9DKRU0",
        "outputId": "c2c896f6-c987-4700-f17d-76653bdb7552"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEkB4mVvKTpc",
        "outputId": "8229c9a3-351b-47ea-e541-207b39da52d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_2J_1DKWOs",
        "outputId": "dd9ff62b-c953-4437-ba8a-83ee159d313f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.],\n",
            "        [133., 133., 133., 133.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDX25scXKYUF",
        "outputId": "8a754b16-fe57-4d54-8bbe-face0180b790"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bridge with NumPy"
      ],
      "metadata": {
        "id": "7ze6RMF8KbFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t= torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a30CMKjqKbu1",
        "outputId": "fbccdbc5-5467-4b33-fb67-0b6f35de3af1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "n= np.add(n, 1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Pu2PuVKgXF",
        "outputId": "fe9ab958-34cb-449e-cd50-47dd1e203d8b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentiation in Autograd"
      ],
      "metadata": {
        "id": "ogHiiKZrKktM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "0m0s_IbRKke-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "metadata": {
        "id": "Mt9IrIguKqHF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)"
      ],
      "metadata": {
        "id": "_02h7O3OvZmM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF3wGH12Kvt7",
        "outputId": "3448563a-0f9a-4a6a-e8a3-8d0b1f07b195"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "q6kndIBeLKLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use autograd to compute the gradients of Y w.r.t. x1 and x2 at the point\n",
        "(x1, x2) = (1, 1). Where\n",
        "Y = (3x1 − 2x2 − 2)2\n",
        ".\n",
        "Verify your results by computing the gradients analytically."
      ],
      "metadata": {
        "id": "J0TT2OgsuwMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# point x1, x2 (1, 1)\n",
        "x1 = torch.tensor(1., requires_grad=True)\n",
        "x2 = torch.tensor(1., requires_grad=True)"
      ],
      "metadata": {
        "id": "lBJ4BhFmLKkU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = (3*x1 - 2*x2 - 2) ** 2"
      ],
      "metadata": {
        "id": "xtP5jvZKLOrF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_grad = torch.tensor(1.)\n",
        "Q.backward(gradient=external_grad)"
      ],
      "metadata": {
        "id": "VfNLkdBeLQWM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "# hard written differenatiated\n",
        "dx1 = 2 * (3*x1 - 2*x2 - 2) * (3)\n",
        "dx2 = 2 * (3*x1 - 2*x2 - 2) * (-2)\n",
        "\n",
        "print(dx1 == x1.grad)\n",
        "print(dx2 == x2.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeS7QVJHLT-E",
        "outputId": "d11b42e9-cbe5-4a1a-dc7b-04dadbad61df"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(True)\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Building Models with PyTorch"
      ],
      "metadata": {
        "id": "6R54zMCxwsDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the network"
      ],
      "metadata": {
        "id": "LUbyDZD-LQ7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # an affine operation: y = Wx + b\n",
        "    # 784 is the input dimension, and 68 is the output dimenstion of the first hidden layer\n",
        "    self.fc1 = nn.Linear(784, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply the first layer with relu activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzsegdkrLW2U",
        "outputId": "a871f0a1-0ad6-4be2-9ecd-facb038547de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLb-M0SoLcSM",
        "outputId": "96381b39-dfaa-4c29-915a-f006f2f40497"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "torch.Size([64, 784])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Identify what are the parameters that are printed in the previous code"
      ],
      "metadata": {
        "id": "-FXVQwooLiIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([64, 784]): This represents the weight matrix for the first layer of the neural network. It has a size of 64 (output features) by 784 (input features).\n",
        "\n",
        "torch.Size([64]): This represents the bias vector for the first layer. It has a size of 64, corresponding to the number of output features in the first layer.\n",
        "\n",
        "torch.Size([64, 64]): This represents the weight matrix for the second layer of the neural network. It has a size of 64 (output features) by 64 (input features).\n",
        "\n",
        "torch.Size([64]): This represents the bias vector for the second layer. It has a size of 64, corresponding to the number of output features in the second layer.\n",
        "\n",
        "torch.Size([10, 64]): This represents the weight matrix for the third (output) layer of the neural network. It has a size of 10 (output classes) by 64 (input features from the previous layer).\n",
        "\n",
        "torch.Size([10]): This represents the bias vector for the third layer. It has a size of 10, corresponding to the number of output classes in the network.\n",
        "\n"
      ],
      "metadata": {
        "id": "mYg3BTQaLjO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(1, 784)\n",
        "out = net(input)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4HJdNvJLmm0",
        "outputId": "417c88cb-47b7-4168-87f6-a3dff0db6e10"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1680,  0.0820, -0.0168,  0.1511,  0.0829,  0.1713, -0.0058,  0.1441,\n",
            "         -0.0026,  0.0038]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Try the previous network with a random mini-batch of size 4 and print its output."
      ],
      "metadata": {
        "id": "NH-ajtpWLqzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(4, 784)\n",
        "out = net(input)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymAfItNTLno0",
        "outputId": "19d26b4f-3f6b-45fa-f154-fbe2afc72b17"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1179,  0.0553,  0.1606,  0.1887, -0.1053,  0.0420,  0.0742,  0.1348,\n",
            "         -0.0956,  0.0824],\n",
            "        [ 0.0577,  0.0276,  0.1748,  0.2251, -0.0097,  0.0927, -0.0222,  0.0555,\n",
            "         -0.1224,  0.0247],\n",
            "        [-0.0211,  0.0546,  0.1255,  0.1305, -0.0790,  0.0969,  0.0201,  0.0492,\n",
            "         -0.1010,  0.0420],\n",
            "        [-0.0240,  0.2125,  0.1586,  0.1695, -0.0252,  0.1166,  0.0425, -0.0533,\n",
            "         -0.1734,  0.0528]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a Loss function and optimizer"
      ],
      "metadata": {
        "id": "m-bZyHwMLxL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Sj8XUashLx4s"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading a Dataset"
      ],
      "metadata": {
        "id": "6wzwuJhmL2M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "  root=\"data\",\n",
        "  train=True,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "  root=\"data\",\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbkEUZIGLzzE",
        "outputId": "24ac7b88-a8b6-48fe-821a-fe12da5c43a3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 5104420.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 134604.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1273714.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3217451.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterating and Visualizing the Dataset"
      ],
      "metadata": {
        "id": "vg6rnomvL-3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(\"digit:\" + str(label))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "amsznjbPL_PM",
        "outputId": "1a0f1a67-b801-4f92-9c68-7abdbdca4525"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing your data for training with DataLoaders"
      ],
      "metadata": {
        "id": "PuuzJ8yMMFfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "XfdwASa7MF6E"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterate through the DataLoader"
      ],
      "metadata": {
        "id": "y83tdLkdMJaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "sBRf--4qMJwV",
        "outputId": "5c77611c-6787-43ee-fe40-6d261aa3bd98"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([4, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAc0ElEQVR4nO3df2yV5f3/8dcp0CNqe7pa+ksKFlDYRGqG0nVqxdHQ1s2BkgWYLnUxENjBqExdOkXUmXVj2ebcEKdZQCP4KxGIZpJgsSVuBQdKmMNV2nRSAi2TpOeUYgtrr+8ffD0fj7TgfTin79PyfCRXwrnv+9377eVNX9zn3L3qc845AQAwyFKsGwAAnJ8IIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYad3Al/X19enQoUNKS0uTz+ezbgcA4JFzTp2dncrPz1dKysD3OUkXQIcOHVJBQYF1GwCAc9Ta2qqxY8cOuD/p3oJLS0uzbgEAEAdn+36esABavXq1LrvsMl1wwQUqLi7We++995XqeNsNAIaHs30/T0gAvfLKK1q+fLlWrlyp999/X0VFRSovL9eRI0cScToAwFDkEmDGjBkuGAxGXvf29rr8/HxXU1Nz1tpQKOQkMRgMBmOIj1AodMbv93G/Azpx4oR2796tsrKyyLaUlBSVlZWpoaHhtON7enoUDoejBgBg+It7AH366afq7e1VTk5O1PacnBy1tbWddnxNTY0CgUBk8AQcAJwfzJ+Cq66uVigUiozW1lbrlgAAgyDuPweUlZWlESNGqL29PWp7e3u7cnNzTzve7/fL7/fHuw0AQJKL+x1Qamqqpk+frtra2si2vr4+1dbWqqSkJN6nAwAMUQlZCWH58uWqqqrSNddcoxkzZujJJ59UV1eXfvzjHyfidACAISghATR//nz997//1SOPPKK2tjZdffXV2rJly2kPJgAAzl8+55yzbuKLwuGwAoGAdRsAgHMUCoWUnp4+4H7zp+AAAOcnAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYGGndAJAIl112WUx1wWDQc83EiRM918yZM8dzzbvvvuu5ZtOmTZ5rJGn9+vWea44cORLTuXD+4g4IAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACZ9zzlk38UXhcFiBQMC6DSTIpEmTPNc899xznmumTZvmuUZSUl97Pp/Pc02sf70/+ugjzzWVlZWeaw4ePOi5BkNHKBRSenr6gPu5AwIAmCCAAAAm4h5Ajz76qHw+X9SYMmVKvE8DABjiEvIL6a688kq9/fbb/3eSkfzeOwBAtIQkw8iRI5Wbm5uILw0AGCYS8hnQ/v37lZ+frwkTJuj222/XgQMHBjy2p6dH4XA4agAAhr+4B1BxcbHWrVunLVu2aM2aNWppadENN9ygzs7Ofo+vqalRIBCIjIKCgni3BABIQnEPoMrKSv3gBz/QtGnTVF5err/+9a/q6OjQq6++2u/x1dXVCoVCkdHa2hrvlgAASSjhTwdkZGToiiuuUFNTU7/7/X6//H5/otsAACSZhP8c0LFjx9Tc3Ky8vLxEnwoAMITEPYDuv/9+1dfX6z//+Y/+/ve/69Zbb9WIESO0cOHCeJ8KADCExf0tuIMHD2rhwoU6evSoxowZo+uvv147duzQmDFj4n0qAMAQxmKkiFksK1y89dZbnmvGjRvnuWYwL+tYfnSgp6fHc012drbnmsGch23btnmuufnmmz3X/O9///NcAxssRgoASEoEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBgpYp7vvXv3eq659NJLPdf4fD7PNUeOHPFcI0nPP/+855o//elPnmsOHjzouWbx4sWea2pqajzXSLFfE15VVFR4rnn77bcT0AkSgcVIAQBJiQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgYqR1A7DX19cXU113d3ecO4mf1atXx1T3xBNPxLmT+Hn22WcH7VxPP/30oJznoYce8lzDatjDB3dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPicc866iS8Kh8MKBALWbeArmDFjhuea+vp6zzV+v99zTayX9eOPP+655rHHHovpXMmsvb3dc01WVlYCOjndiBEjBuU8OHehUEjp6ekD7ucOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImR1g1g6Hrvvfc819xwww2eay666CLPNRMmTPBcI0mdnZ0x1Q03mzZt8lxz1113xb8RDGvcAQEATBBAAAATngNo+/btuuWWW5Sfny+fz3farbpzTo888ojy8vI0evRolZWVaf/+/fHqFwAwTHgOoK6uLhUVFWn16tX97l+1apWeeuopPfPMM9q5c6cuuugilZeXq7u7+5ybBQAMH54fQqisrFRlZWW/+5xzevLJJ/Xwww9rzpw5kqQXXnhBOTk52rRpkxYsWHBu3QIAho24fgbU0tKitrY2lZWVRbYFAgEVFxeroaGh35qenh6Fw+GoAQAY/uIaQG1tbZKknJycqO05OTmRfV9WU1OjQCAQGQUFBfFsCQCQpMyfgquurlYoFIqM1tZW65YAAIMgrgGUm5srSWpvb4/a3t7eHtn3ZX6/X+np6VEDADD8xTWACgsLlZubq9ra2si2cDisnTt3qqSkJJ6nAgAMcZ6fgjt27Jiampoir1taWrRnzx5lZmZq3Lhxuvfee/XEE0/o8ssvV2FhoVasWKH8/HzNnTs3nn0DAIY4zwG0a9cu3XTTTZHXy5cvlyRVVVVp3bp1evDBB9XV1aXFixero6ND119/vbZs2aILLrggfl0DAIY8n3POWTfxReFwWIFAwLoN4Ly2cuVKzzUrVqxIQCen+/a3v+25JpaFc3HuQqHQGT/XN38KDgBwfiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmPD86xgARMvIyPBcc/XVV3uuKS0t9Vxz5ZVXeq6RpG984xsx1Q2Gp59+2nNNc3NzTOfatWuX55qtW7d6rtmzZ4/nmuGAOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmfM45Z93EF4XDYQUCAes2MMTNnTs3prqHHnrIc01mZqbnmvHjx3uu8fl8nmuS7K93XCT7PBw/ftxzzY9+9CPPNZs3b/ZcM9hCoZDS09MH3M8dEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMsRgplZ2fHVFdUVOS55vvf/77nmmAw6LkmyS7ruEhJ8f7vxb6+vgR0Yot5OGXEiBHWLZwVi5ECAJISAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEyOtG0B8zZw503PN6tWrYzrX5MmTY6rzKpaFRWNdjHTfvn2DUhOLNWvWDMp5JOn111/3XDNYiwgvW7bMc83x48djOlcsfzdSU1NjOtf5iDsgAIAJAggAYMJzAG3fvl233HKL8vPz5fP5tGnTpqj9d955p3w+X9SoqKiIV78AgGHCcwB1dXWpqKjojO+NVlRU6PDhw5Hx0ksvnVOTAIDhx/NDCJWVlaqsrDzjMX6/X7m5uTE3BQAY/hLyGVBdXZ2ys7M1efJkLV26VEePHh3w2J6eHoXD4agBABj+4h5AFRUVeuGFF1RbW6tf//rXqq+vV2VlpXp7e/s9vqamRoFAIDIKCgri3RIAIAnF/eeAFixYEPnzVVddpWnTpmnixImqq6vTrFmzTju+urpay5cvj7wOh8OEEACcBxL+GPaECROUlZWlpqamfvf7/X6lp6dHDQDA8JfwADp48KCOHj2qvLy8RJ8KADCEeH4L7tixY1F3My0tLdqzZ48yMzOVmZmpxx57TPPmzVNubq6am5v14IMPatKkSSovL49r4wCAoc1zAO3atUs33XRT5PXnn99UVVVpzZo12rt3r55//nl1dHQoPz9fs2fP1i9+8Qv5/f74dQ0AGPJ8LtZVGxMkHA4P2qKGyW7RokWea5566inPNaNGjfJcM5g+/vhjzzULFy6M6VwDfVZ5Jl1dXTGdazBcc801MdVt27bNc82FF17oueazzz7zXJOWlua5Zv78+Z5rJOnFF1/0XOPz+WI6l1cjRyb/WtKhUOiMn+uzFhwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETyL6d6HnvmmWc81wzm4uYdHR2ea6qrqz3XPPfcc55rcMqqVatiqotlZetY/PKXvxyU83zve9+LqS6Wla337dvnuebxxx/3XDMccAcEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAhM8N5uqVX0E4HFYgELBuIyn09vZ6rhnM/51Lly71XMPCorF7+OGHPdc8+OCDMZ0rlsVIDx065LlmxowZnmva2to816Snp3uukaSxY8d6runq6vJc88knn3iuGQpCodAZ5547IACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZGWjeAgXV0dHiuycjIiHsfA5k6deqgnSuZFRQUeK5ZtGiR55oVK1Z4runr6/NcI8W2EO4f/vAHzzWxLCwai3A4HFPdvn374twJvog7IACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZYjDSJLViwwHPNW2+9lYBO+nfHHXd4rvnXv/7luebZZ5/1XDNz5kzPNZJUWVnpuaaqqspzTVZWlueaWBYWdc55rpGkhx56yHPNb3/725jOhfMXd0AAABMEEADAhKcAqqmp0bXXXqu0tDRlZ2dr7ty5amxsjDqmu7tbwWBQl1xyiS6++GLNmzdP7e3tcW0aADD0eQqg+vp6BYNB7dixQ1u3btXJkyc1e/ZsdXV1RY6577779MYbb+i1115TfX29Dh06pNtuuy3ujQMAhjZPDyFs2bIl6vW6deuUnZ2t3bt3q7S0VKFQSH/5y1+0YcMGfec735EkrV27Vl//+te1Y8cOfetb34pf5wCAIe2cPgMKhUKSpMzMTEnS7t27dfLkSZWVlUWOmTJlisaNG6eGhoZ+v0ZPT4/C4XDUAAAMfzEHUF9fn+69915dd911mjp1qqRTv989NTVVGRkZUcfm5OQM+Lvfa2pqFAgEIqOgoCDWlgAAQ0jMARQMBvXhhx/q5ZdfPqcGqqurFQqFIqO1tfWcvh4AYGiI6QdRly1bpjfffFPbt2/X2LFjI9tzc3N14sQJdXR0RN0Ftbe3Kzc3t9+v5ff75ff7Y2kDADCEeboDcs5p2bJl2rhxo7Zt26bCwsKo/dOnT9eoUaNUW1sb2dbY2KgDBw6opKQkPh0DAIYFT3dAwWBQGzZs0ObNm5WWlhb5XCcQCGj06NEKBAK66667tHz5cmVmZio9PV133323SkpKeAIOABDFUwCtWbNG0unrbK1du1Z33nmnJOn3v/+9UlJSNG/ePPX09Ki8vFxPP/10XJoFAAwfPhfraoUJEg6HFQgErNtICiNHev+I7p133vFck+xvjx49etRzTXp6ekznGjVqVEx1g+Hjjz/2XLNw4cKYzvXPf/7Tc00si6VieAuFQmf8u8hacAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE6yGPczceOONnmsqKytjOldVVZXnmjFjxniu8fl8nmsG87Lu6OjwXLN+/XrPNffcc4/nGsASq2EDAJISAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEyxGipgVFxd7rrnjjjsS0En8/OMf//BcU19f77nmk08+8VwDDDUsRgoASEoEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBgpACAhWIwUAJCUCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgwlMA1dTU6Nprr1VaWpqys7M1d+5cNTY2Rh0zc+ZM+Xy+qLFkyZK4Ng0AGPo8BVB9fb2CwaB27NihrVu36uTJk5o9e7a6urqijlu0aJEOHz4cGatWrYpr0wCAoW+kl4O3bNkS9XrdunXKzs7W7t27VVpaGtl+4YUXKjc3Nz4dAgCGpXP6DCgUCkmSMjMzo7avX79eWVlZmjp1qqqrq3X8+PEBv0ZPT4/C4XDUAACcB1yMent73Xe/+1133XXXRW3/85//7LZs2eL27t3rXnzxRXfppZe6W2+9dcCvs3LlSieJwWAwGMNshEKhM+ZIzAG0ZMkSN378eNfa2nrG42pra50k19TU1O/+7u5uFwqFIqO1tdV80hgMBoNx7uNsAeTpM6DPLVu2TG+++aa2b9+usWPHnvHY4uJiSVJTU5MmTpx42n6/3y+/3x9LGwCAIcxTADnndPfdd2vjxo2qq6tTYWHhWWv27NkjScrLy4upQQDA8OQpgILBoDZs2KDNmzcrLS1NbW1tkqRAIKDRo0erublZGzZs0M0336xLLrlEe/fu1X333afS0lJNmzYtIf8BAIAhysvnPhrgfb61a9c655w7cOCAKy0tdZmZmc7v97tJkya5Bx544KzvA35RKBQyf9+SwWAwGOc+zva93/f/gyVphMNhBQIB6zYAAOcoFAopPT19wP2sBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJF0AeScs24BABAHZ/t+nnQB1NnZad0CACAOzvb93OeS7Jajr69Phw4dUlpamnw+X9S+cDisgoICtba2Kj093ahDe8zDKczDKczDKczDKckwD845dXZ2Kj8/XykpA9/njBzEnr6SlJQUjR079ozHpKenn9cX2OeYh1OYh1OYh1OYh1Os5yEQCJz1mKR7Cw4AcH4ggAAAJoZUAPn9fq1cuVJ+v9+6FVPMwynMwynMwynMwylDaR6S7iEEAMD5YUjdAQEAhg8CCABgggACAJgggAAAJoZMAK1evVqXXXaZLrjgAhUXF+u9996zbmnQPfroo/L5fFFjypQp1m0l3Pbt23XLLbcoPz9fPp9PmzZtitrvnNMjjzyivLw8jR49WmVlZdq/f79Nswl0tnm48847T7s+KioqbJpNkJqaGl177bVKS0tTdna25s6dq8bGxqhjuru7FQwGdckll+jiiy/WvHnz1N7ebtRxYnyVeZg5c+Zp18OSJUuMOu7fkAigV155RcuXL9fKlSv1/vvvq6ioSOXl5Tpy5Ih1a4Puyiuv1OHDhyPj3XfftW4p4bq6ulRUVKTVq1f3u3/VqlV66qmn9Mwzz2jnzp266KKLVF5eru7u7kHuNLHONg+SVFFREXV9vPTSS4PYYeLV19crGAxqx44d2rp1q06ePKnZs2erq6srcsx9992nN954Q6+99prq6+t16NAh3XbbbYZdx99XmQdJWrRoUdT1sGrVKqOOB+CGgBkzZrhgMBh53dvb6/Lz811NTY1hV4Nv5cqVrqioyLoNU5Lcxo0bI6/7+vpcbm6u+81vfhPZ1tHR4fx+v3vppZcMOhwcX54H55yrqqpyc+bMMenHypEjR5wkV19f75w79f9+1KhR7rXXXosc89FHHzlJrqGhwarNhPvyPDjn3I033ujuueceu6a+gqS/Azpx4oR2796tsrKyyLaUlBSVlZWpoaHBsDMb+/fvV35+viZMmKDbb79dBw4csG7JVEtLi9ra2qKuj0AgoOLi4vPy+qirq1N2drYmT56spUuX6ujRo9YtJVQoFJIkZWZmSpJ2796tkydPRl0PU6ZM0bhx44b19fDlefjc+vXrlZWVpalTp6q6ulrHjx+3aG9ASbcY6Zd9+umn6u3tVU5OTtT2nJwc/fvf/zbqykZxcbHWrVunyZMn6/Dhw3rsscd0ww036MMPP1RaWpp1eyba2tokqd/r4/N954uKigrddtttKiwsVHNzs37+85+rsrJSDQ0NGjFihHV7cdfX16d7771X1113naZOnSrp1PWQmpqqjIyMqGOH8/XQ3zxI0g9/+EONHz9e+fn52rt3r372s5+psbFRr7/+umG30ZI+gPB/KisrI3+eNm2aiouLNX78eL366qu66667DDtDMliwYEHkz1dddZWmTZumiRMnqq6uTrNmzTLsLDGCwaA+/PDD8+Jz0DMZaB4WL14c+fNVV12lvLw8zZo1S83NzZo4ceJgt9mvpH8LLisrSyNGjDjtKZb29nbl5uYadZUcMjIydMUVV6ipqcm6FTOfXwNcH6ebMGGCsrKyhuX1sWzZMr355pt65513on59S25urk6cOKGOjo6o44fr9TDQPPSnuLhYkpLqekj6AEpNTdX06dNVW1sb2dbX16fa2lqVlJQYdmbv2LFjam5uVl5ennUrZgoLC5Wbmxt1fYTDYe3cufO8vz4OHjyoo0ePDqvrwzmnZcuWaePGjdq2bZsKCwuj9k+fPl2jRo2Kuh4aGxt14MCBYXU9nG0e+rNnzx5JSq7rwfopiK/i5Zdfdn6/361bt87t27fPLV682GVkZLi2tjbr1gbVT3/6U1dXV+daWlrc3/72N1dWVuaysrLckSNHrFtLqM7OTvfBBx+4Dz74wElyv/vd79wHH3zgPvnkE+ecc7/61a9cRkaG27x5s9u7d6+bM2eOKywsdJ999plx5/F1pnno7Ox0999/v2toaHAtLS3u7bffdt/85jfd5Zdf7rq7u61bj5ulS5e6QCDg6urq3OHDhyPj+PHjkWOWLFnixo0b57Zt2+Z27drlSkpKXElJiWHX8Xe2eWhqanKPP/6427Vrl2tpaXGbN292EyZMcKWlpcadRxsSAeScc3/84x/duHHjXGpqqpsxY4bbsWOHdUuDbv78+S4vL8+lpqa6Sy+91M2fP981NTVZt5Vw77zzjpN02qiqqnLOnXoUe8WKFS4nJ8f5/X43a9Ys19jYaNt0ApxpHo4fP+5mz57txowZ40aNGuXGjx/vFi1aNOz+kdbff78kt3bt2sgxn332mfvJT37ivva1r7kLL7zQ3Xrrre7w4cN2TSfA2ebhwIEDrrS01GVmZjq/3+8mTZrkHnjgARcKhWwb/xJ+HQMAwETSfwYEABieCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmPh/pS1XUfcoLEoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the network"
      ],
      "metadata": {
        "id": "0Z48WsakMQh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0G9HHPaMRL1",
        "outputId": "b97d674d-1bba-44f3-95b2-d1d1c7e9b215"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.264\n",
            "[1,  4000] loss: 2.118\n",
            "[1,  6000] loss: 1.717\n",
            "[1,  8000] loss: 1.183\n",
            "[1, 10000] loss: 0.833\n",
            "[1, 12000] loss: 0.655\n",
            "[1, 14000] loss: 0.572\n",
            "[2,  2000] loss: 0.502\n",
            "[2,  4000] loss: 0.463\n",
            "[2,  6000] loss: 0.446\n",
            "[2,  8000] loss: 0.401\n",
            "[2, 10000] loss: 0.384\n",
            "[2, 12000] loss: 0.401\n",
            "[2, 14000] loss: 0.350\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: What is the meaning of epoch, forward pass, backward pass. What is the effect of torch.flatten(inputs, 1), and optimizer.step()?"
      ],
      "metadata": {
        "id": "sCr_DQzYMkR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch:  the one entire passing of training data through the algorithm. The outer loop for epoch in range(2) indicates that the training process will loop over the dataset two times.\n",
        "\n",
        "Forward Pass:  the calculation and storage of intermediate variables (including outputs) for a neural network in order from the input layer to the output layer. In this code, outputs = net(torch.flatten(inputs, 1)) represents the forward pass, where inputs are passed through the neural network (net) after being flattened along the second dimension using torch.flatten(inputs, 1).\n",
        "\n",
        "Backward Pass: Backward Pass(Backpropagation) is to calculate a gradient using the mean(average) of the sum of the losses(differences) between the model's predictions and true values(train data), working from output layer to input layer. This is done using the backward() method: iteration_loss.backward(). It computes gradients for all the tensors used to compute iteration_loss.\n",
        "\n",
        "Optimizer: optimizer.step() updates the parameters of the neural network using the computed gradients and the optimization algorithm like  SGD, and Adam; to minimize the loss. It adjusts the network's weights and biases based on the computed gradients and the specified optimization strategy.\n",
        "\n",
        "torch.flatten(inputs, 1): This function reshapes the input tensor inputs to have a flattened shape along (dimension 1). It's used to prepare the input data for the neural network because it expects a flattened representation."
      ],
      "metadata": {
        "id": "7Ax-2OHqMrRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './my_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "GFzBSh2bMw_8"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the network on the test data"
      ],
      "metadata": {
        "id": "zKj_JG5DM3Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzZiaiY7M308",
        "outputId": "9aba04f6-5a78-45bf-8131-cbef386df010"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3D0jabyM8B8",
        "outputId": "d77e11e8-eb48-41bf-d41c-310a3a34f718"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 89 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Train the network in the previous example, but instead of using 2 hidden layers, try 3 hidden layers."
      ],
      "metadata": {
        "id": "DSYKpAOVNA64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Setup data loaders\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "fTDbFPNxP_Tr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the neural network model\n",
        "class ThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Example for MNIST dataset, 28*28 = 784 input features\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)    # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the network\n",
        "net = ThreeHiddenLayerNet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1)  # Flatten the images\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 200 == 199:  # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Testing the network\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        images = torch.flatten(images, start_dim=1)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDenlldNOBqU",
        "outputId": "5fd140e5-8442-4084-9d21-ae6d77bfe79f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 2.302\n",
            "[1,   400] loss: 2.296\n",
            "[1,   600] loss: 2.293\n",
            "[1,   800] loss: 2.288\n",
            "[2,   200] loss: 2.276\n",
            "[2,   400] loss: 2.268\n",
            "[2,   600] loss: 2.265\n",
            "[2,   800] loss: 2.254\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 20 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "low accuracy"
      ],
      "metadata": {
        "id": "dc0sjpaC-UNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: Train the network in the previous example\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "using Adam optimizer"
      ],
      "metadata": {
        "id": "P24qPC9-QcfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the neural network model\n",
        "class ThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Example for MNIST dataset, 28*28 = 784 input features\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)    # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the network\n",
        "net = ThreeHiddenLayerNet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Use Adam optimizer\n",
        "\n",
        "# Prepare the dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1)  # Flatten the images\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 200 == 199:  # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Testing the network\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        images = torch.flatten(images, start_dim=1)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ],
      "metadata": {
        "id": "SwC28BWXgDOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1afa627-fb13-4e0e-94f5-42bd6b344893"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 0.811\n",
            "[1,   400] loss: 0.368\n",
            "[1,   600] loss: 0.321\n",
            "[1,   800] loss: 0.278\n",
            "[2,   200] loss: 0.212\n",
            "[2,   400] loss: 0.210\n",
            "[2,   600] loss: 0.188\n",
            "[2,   800] loss: 0.176\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 94 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy has signficatlly increased"
      ],
      "metadata": {
        "id": "GfKRDCG3-OIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on GPU"
      ],
      "metadata": {
        "id": "RoeGWOZPRwNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H96023HlRwlZ",
        "outputId": "e461b953-ff0c-480d-b280-ce06340c1cad"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYskKP0R1DE",
        "outputId": "860c2264-1bf6-48ee-d477-52013f231f78"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 7: Train the network in the previous example on GPU. Do you notice significant speedup? if not, try to increase the size of your network."
      ],
      "metadata": {
        "id": "-LyjoD8hR4g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we try on small network."
      ],
      "metadata": {
        "id": "bh-XgBqaST3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGq7HldtR43M",
        "outputId": "2e4d0643-b297-4922-813a-eadfc0806b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU time: 46s\n",
        "\n",
        "GPU time: 56s\n",
        "\n",
        "The speed up isn't noticable, even though the CPU is faster, so we will increase the size of the network"
      ],
      "metadata": {
        "id": "WUUV3VysSIlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LargerThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LargerThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)  # First hidden layer with 128 neurons\n",
        "        self.fc2 = nn.Linear(512, 512)  # Second hidden layer with 128 neurons\n",
        "        self.fc3 = nn.Linear(512, 10)   # Output layer with 10 neurons\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))   # ReLU activation for first hidden layer\n",
        "        x = torch.relu(self.fc2(x))   # ReLU activation for second hidden layer\n",
        "        x = self.fc3(x)               # Output layer without activation (for example, using CrossEntropyLoss)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oBpCBZTfSJI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming net is the previously defined neural network with 3 hidden layers\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "# Initialize the larger network and move it to the device (GPU if available)\n",
        "net = LargerThreeHiddenLayerNet().to(device)\n",
        "\n",
        "# Define the loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Adam optimizer with a learning rate of 0.001\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Assuming train_dataloader contains your training dataset\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        # Move the inputs and labels to the device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr12_59OSNNk",
        "outputId": "c38de079-a102-48ac-93bd-4df9c13962c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU time: 1m 17s\n",
        "\n",
        "CPU time: 7m 28s\n"
      ],
      "metadata": {
        "id": "cvQGuOTqSQa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see the power of using GPU for trainning, we can see the huge difference in time !"
      ],
      "metadata": {
        "id": "pvMavyfs_NQW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjDnp_cp_LU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}